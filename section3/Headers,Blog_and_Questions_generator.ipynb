{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cad044b9563d430a9331245d1464686d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_92e980ec795747fcb6a22770e78256d8",
              "IPY_MODEL_82e55807e1034b0daeec95f9b7e62e00",
              "IPY_MODEL_b0e06b25eebd4cab9876811dd26ccab1"
            ],
            "layout": "IPY_MODEL_febb84525b3840ebbd730e608eeaa32c"
          }
        },
        "92e980ec795747fcb6a22770e78256d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9972c370670498a9934b2ee1ff7c2fd",
            "placeholder": "​",
            "style": "IPY_MODEL_26b87ffdb6804a24868a793222ef147b",
            "value": "Map: 100%"
          }
        },
        "82e55807e1034b0daeec95f9b7e62e00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83c93944c623442fa125e420155cf90a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_100d34679b64419eb47e9df0b9820003",
            "value": 1
          }
        },
        "b0e06b25eebd4cab9876811dd26ccab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1b4c388a5dd41ba84e2ac6e8b4d635c",
            "placeholder": "​",
            "style": "IPY_MODEL_96b75c60288c43c5bea07b78338d93a9",
            "value": " 1/1 [00:01&lt;00:00,  1.45s/ examples]"
          }
        },
        "febb84525b3840ebbd730e608eeaa32c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9972c370670498a9934b2ee1ff7c2fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26b87ffdb6804a24868a793222ef147b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83c93944c623442fa125e420155cf90a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "100d34679b64419eb47e9df0b9820003": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1b4c388a5dd41ba84e2ac6e8b4d635c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96b75c60288c43c5bea07b78338d93a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KTZaJePVJF3t"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-L7hzmHcUQwy",
        "outputId": "924f419c-9656-4c1c-ad8a-d1951c5e2d55"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# our first task is to find meaningful sentences/para from blog\n",
        "\n",
        "> lets test with sample blog\n",
        "\n"
      ],
      "metadata": {
        "id": "sTwvdmjiKtAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "\n",
        "def split_into_meaningful_paragraphs(text, min_sentences=3, max_sentences=10, similarity_threshold=0.3):\n",
        "    #split the text into sentences\n",
        "    sentences = sent_tokenize(text)\n",
        "    #initialize paragraphs\n",
        "    paragraphs = []\n",
        "    current_paragraph = []\n",
        "\n",
        "    #TF-IDF vectorizer for calculating sentence similarity\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        current_paragraph.append(sentence)\n",
        "\n",
        "        #check if we have enough sentences to form a paragraph\n",
        "        if len(current_paragraph) >= min_sentences:\n",
        "            #calculate similarity between the current sentence and the next one\n",
        "            if i + 1 < len(sentences):\n",
        "                current_vec = vectorizer.fit_transform([' '.join(current_paragraph), sentences[i+1]])\n",
        "                similarity = cosine_similarity(current_vec[0], current_vec[1])[0][0]\n",
        "\n",
        "                #if similarity is low or we've reached max sentences, start a new paragraph\n",
        "                if similarity < similarity_threshold or len(current_paragraph) >= max_sentences:\n",
        "                    paragraphs.append(' '.join(current_paragraph))\n",
        "                    current_paragraph = []\n",
        "\n",
        "    #add any remaining sentences as the last paragraph\n",
        "    if current_paragraph:\n",
        "        paragraphs.append(' '.join(current_paragraph))\n",
        "\n",
        "    return paragraphs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IALfmxymJT-g",
        "outputId": "d1a06d40-cb5a-461e-eec2-e9764824e7b9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary = \"\"\"The Future of AI in Healthcare\n",
        "Introduction: AI's Revolutionary Impact on Healthcare\n",
        "Artificial Intelligence (AI) is poised to revolutionize the healthcare industry. From diagnosis to treatment planning, AI technologies are being integrated into various aspects of medical care. This integration promises to improve patient outcomes, reduce costs, and enhance the efficiency of healthcare systems worldwide.\n",
        "Early Detection and Diagnosis\n",
        "One of the most promising applications of AI in healthcare is in early detection and diagnosis of diseases. Machine learning algorithms can analyze medical images, such as X-rays, MRIs, and CT scans, with remarkable accuracy. These AI systems can often detect subtle abnormalities that might be overlooked by human radiologists, leading to earlier diagnoses and potentially life-saving interventions.\n",
        "Personalized Treatment Plans\n",
        "AI is also making significant strides in developing personalized treatment plans. By analyzing vast amounts of patient data, including genetic information, medical history, and lifestyle factors, AI algorithms can recommend tailored treatment options. This approach, known as precision medicine, allows healthcare providers to offer more effective and targeted therapies, minimizing side effects and improving overall patient care.\n",
        "Drug Discovery and Development\n",
        "The pharmaceutical industry is leveraging AI to accelerate drug discovery and development processes. Machine learning models can predict how potential drug compounds will interact with biological targets, significantly reducing the time and cost associated with traditional drug development methods. This could lead to faster development of new treatments for a wide range of diseases.\n",
        "Administrative Efficiency and Cost Reduction\n",
        "Beyond clinical applications, AI is also being used to streamline administrative tasks in healthcare settings. Natural language processing and machine learning algorithms can automate tasks such as medical coding, billing, and appointment scheduling. This not only reduces the administrative burden on healthcare professionals but also helps to minimize errors and improve overall efficiency.\n",
        "Challenges and Ethical Considerations\n",
        "While the potential benefits of AI in healthcare are immense, there are also significant challenges and ethical considerations to address. Issues such as data privacy, algorithmic bias, and the need for human oversight in AI-driven decision-making processes must be carefully managed. Ensuring that AI technologies are developed and implemented responsibly will be crucial for maintaining public trust and maximizing the benefits of these innovations.\n",
        "Conclusion: A Collaborative Future\n",
        "The future of AI in healthcare is not about replacing human medical professionals, but rather about augmenting their capabilities. By combining the analytical power of AI with the experience and intuition of healthcare providers, we can create a more effective, efficient, and patient-centered healthcare system. As AI continues to evolve, its impact on healthcare will undoubtedly grow, ushering in a new era of medical innovation and improved patient care.\"\"\""
      ],
      "metadata": {
        "id": "8pJzDAm0JZrQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "structured_blog = split_into_meaningful_paragraphs(summary)\n",
        "print(structured_blog)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MT4vp8IAJeMQ",
        "outputId": "9d844ae7-c451-433f-875c-8638f95e0bf9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['But I also blame the people of the United States who can’t put their plans on hold for a little longer in order to remain safe, and for the health and well-being of others. Consistently masking up, only going out when absolutely necessary, and avoiding crowds goes a long way towards ending this pandemic. Every time I think people can‘t amaze me further with their stupidity, I’m sadly mistaken.', 'As of today, there have been 13.7m cases of the novel coronavirus, with almost 270k deaths. We’ve been stuck at home since March, invading one another’s space, constantly under each other. We even avoided a small Thanksgiving get-together to ensure we remained virus free.', 'But for all that is holy, stay home this holiday season and plan the vacations for when it’ll be safer. I know it sounds crazy, but it‘s true. We have a lot of people who are sick, and we’re not the only ones who are.', 'And we have a great deal of friends and family that are sick. And that’d be great if we could just stay home and plan our vacations for the holidays. But you can”t tell me a crowd the size of the ones that frequent Disney isn’�t a recipe for disaster.', \"But I think it”s a recipe to ending this epidemic. And I”m sadly wrong. I blame the American people who can't put their plan on hold, and I blame them for it.\", 'I“m not a big fan of crowds, but I do know that a crowd that size of people that frequent Walt Disney World is a recipe in itself for disaster, and that“s not a good thing.” But I blame people of all stripes for being so stupid, and so stupid that they can“stuck at home” for a long time. I don“t know what to do with all that money. I just know that the people who live in this country are the ones who have the most money, and the most time to spend with their families.', 'And so, I think we should all take advantage of that money and go out and enjoy the holiday season. And if you don’“stay home“, I blame you. I think that” is a good idea.', 'But it“doesn”“Stay home this Christmas season” doesn“And plan the holidays for the vacations that are safer,” I say. “Stay away from the crowds.“But for all of the people in the country, stay at home. Stay away from those who are too busy to be in the crowds, and plan their vacations.’ “We” are the people that live in the US, and who are the most vulnerable.', '”I“ve been thinking about how to avoid crowds. I want to be able to stay away from them. I also want to stay home, because I know that people are going to be the ones to stay safe.', 'And to stay out of the crowds that invade our space. And, I want my family to be safe.‘I want to make sure that we stay safe,“I want my kids to stay healthy.\\u202c”I think people should know that, too. I mean, if they want to have a holiday, they should stay home. But if they can stay home for a while, they can do that.„I want them to stay in their space.″I want the people to stay on the road.‖I want our families to stay safer.\\u202aI want their kids to have fun. I really want to go to Disney.', 'I need to be there for them. And the people I love. I have to be at home, too, to be with my family.', 'I hope they stay safe and healthy. I would love to stay with my kids. I am a stay-at-home mom. I love my kids, and my wife, too!”So, stay away.', 'I guess that makes sense. But that doesn’T mean that I can stay at Disney. And it doesn‘Treat people as if they are the only one who can stay safe from the pandemic, because they are my family, and not just because I‘m the one who has to go out to Disney, and stay home with me. I believe that, in the meantime, stay in the same place, and make sure they stay healthy and happy.', 'And then I want their families to be happy. But, of course, stay safe because I want the vacations to be healthy. And for all the people at Disney, too“We have to stay at Disneyland.', 'And when they stay home to be together. I’ma stay home because I have a family, too…�']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lets structure the paras"
      ],
      "metadata": {
        "id": "fgCvctwhLgCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "J9ttqUsJU_iF",
        "outputId": "38a2e661-8333-4029-cb75-6015d9267a7f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-2.21.0-py3-none-any.whl (527 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, pyarrow, dill, multiprocess, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.21.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-17.0.0 xxhash-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pyarrow"
                ]
              },
              "id": "73a76bf4c08f48b28a55599a797a2142"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset, load_metric, load_dataset\n",
        "from transformers import LEDTokenizer, LEDForConditionalGeneration\n",
        "import torch\n",
        "\n",
        "sample_paragraph = \"Virat kohli is an inspiration to many people around the world\"\n",
        "data = [sample_paragraph]\n",
        "df = pd.DataFrame(data, columns=['Paragraph'])\n",
        "df[\"Paragraph\"][0]\n",
        "df_test = Dataset.from_pandas(df)\n",
        "df_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YC2D5IZ_U8Ne",
        "outputId": "7d50d8d9-ad36-44cc-9d8f-16e306e48678"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['Paragraph'],\n",
              "    num_rows: 1\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = LEDTokenizer.from_pretrained(\"/content/drive/MyDrive/checkpoint-100\")\n",
        "model = LEDForConditionalGeneration.from_pretrained(\"/content/drive/MyDrive/checkpoint-100\").to(\"cuda\").half()\n",
        "\n",
        "def generate_answer(batch):\n",
        "  inputs_dict = tokenizer(batch[\"Paragraph\"], padding=\"max_length\", max_length=512, return_tensors=\"pt\", truncation=True)\n",
        "  input_ids = inputs_dict.input_ids.to(\"cuda\")\n",
        "  attention_mask = inputs_dict.attention_mask.to(\"cuda\")\n",
        "  global_attention_mask = torch.zeros_like(attention_mask)\n",
        "\n",
        "  predicted_abstract_ids = model.generate(input_ids, attention_mask=attention_mask, global_attention_mask=global_attention_mask)\n",
        "  batch[\"generated_heading\"] = tokenizer.batch_decode(predicted_abstract_ids, skip_special_tokens=True)\n",
        "  return batch\n",
        "\n",
        "result = df_test.map(generate_answer, batched=True, batch_size=2)\n",
        "result['generated_heading']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "cad044b9563d430a9331245d1464686d",
            "92e980ec795747fcb6a22770e78256d8",
            "82e55807e1034b0daeec95f9b7e62e00",
            "b0e06b25eebd4cab9876811dd26ccab1",
            "febb84525b3840ebbd730e608eeaa32c",
            "a9972c370670498a9934b2ee1ff7c2fd",
            "26b87ffdb6804a24868a793222ef147b",
            "83c93944c623442fa125e420155cf90a",
            "100d34679b64419eb47e9df0b9820003",
            "c1b4c388a5dd41ba84e2ac6e8b4d635c",
            "96b75c60288c43c5bea07b78338d93a9"
          ]
        },
        "id": "hM8-_ok5VVTs",
        "outputId": "b10b4797-1e94-47c4-e493-cbc6d87eef9c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cad044b9563d430a9331245d1464686d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Input ids are automatically padded from 512 to 1024 to be a multiple of `config.attention_window`: 1024\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Virat kohli']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Yeah our heading generator working !!"
      ],
      "metadata": {
        "id": "PFFdxLJEV1RU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def structure_blog(blog):\n",
        "    paragraphs = split_into_meaningful_paragraphs(blog) # Assuming this function exists and works as expected\n",
        "    structured_blog = []\n",
        "    for paragraph in paragraphs:\n",
        "        # Create a batch dictionary for the current paragraph\n",
        "        batch = {\"Paragraph\": paragraph}\n",
        "        heading = generate_answer(batch)[\"generated_heading\"][0] # Access the generated heading\n",
        "        structured_blog.append(f\"## {heading}\\n\\n{paragraph}\")\n",
        "    return \"\\n\\n\".join(structured_blog)"
      ],
      "metadata": {
        "id": "KTjgMGt_LG02"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = structure_blog(summary)\n",
        "print(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wxj4KV3JU7mL",
        "outputId": "c2f576e0-edf2-4ee6-d9e0-5b14a908bf40"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## The Future of AI in Healthcare\n",
            "\n",
            "The Future of AI in Healthcare\n",
            "Introduction: AI's Revolutionary Impact on Healthcare\n",
            "Artificial Intelligence (AI) is poised to revolutionize the healthcare industry. From diagnosis to treatment planning, AI technologies are being integrated into various aspects of medical care. This integration promises to improve patient outcomes, reduce costs, and enhance the efficiency of healthcare systems worldwide. Early Detection and Diagnosis\n",
            "One of the most promising applications of AI in healthcare is in early detection and diagnosis of diseases.\n",
            "\n",
            "## Artificial Intelligence (AI) is making significant strides in developing personalized treatment plans.\n",
            "\n",
            "Machine learning algorithms can analyze medical images, such as X-rays, MRIs, and CT scans, with remarkable accuracy. These AI systems can often detect subtle abnormalities that might be overlooked by human radiologists, leading to earlier diagnoses and potentially life-saving interventions. Personalized Treatment Plans\n",
            "AI is also making significant strides in developing personalized treatment plans.\n",
            "\n",
            "## Use AI to improve patient care.\n",
            "\n",
            "By analyzing vast amounts of patient data, including genetic information, medical history, and lifestyle factors, AI algorithms can recommend tailored treatment options. This approach, known as precision medicine, allows healthcare providers to offer more effective and targeted therapies, minimizing side effects and improving overall patient care. Drug Discovery and Development\n",
            "The pharmaceutical industry is leveraging AI to accelerate drug discovery and development processes.\n",
            "\n",
            "## Machine learning can improve the delivery of drugs.\n",
            "\n",
            "Machine learning models can predict how potential drug compounds will interact with biological targets, significantly reducing the time and cost associated with traditional drug development methods. This could lead to faster development of new treatments for a wide range of diseases. Administrative Efficiency and Cost Reduction\n",
            "Beyond clinical applications, AI is also being used to streamline administrative tasks in healthcare settings.\n",
            "\n",
            "## Artificial intelligence (AI) can automate a wide range of tasks.\n",
            "\n",
            "Natural language processing and machine learning algorithms can automate tasks such as medical coding, billing, and appointment scheduling. This not only reduces the administrative burden on healthcare professionals but also helps to minimize errors and improve overall efficiency. Challenges and Ethical Considerations\n",
            "While the potential benefits of AI in healthcare are immense, there are also significant challenges and ethical considerations to address.\n",
            "\n",
            "## Develop and implement AI-driven decisions.\n",
            "\n",
            "Issues such as data privacy, algorithmic bias, and the need for human oversight in AI-driven decision-making processes must be carefully managed. Ensuring that AI technologies are developed and implemented responsibly will be crucial for maintaining public trust and maximizing the benefits of these innovations. Conclusion: A Collaborative Future\n",
            "The future of AI in healthcare is not about replacing human medical professionals, but rather about augmenting their capabilities.\n",
            "\n",
            "## Use AI to improve healthcare.\n",
            "\n",
            "By combining the analytical power of AI with the experience and intuition of healthcare providers, we can create a more effective, efficient, and patient-centered healthcare system. As AI continues to evolve, its impact on healthcare will undoubtedly grow, ushering in a new era of medical innovation and improved patient care.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "spliting done :) heading done :) Lets Move on to the questions generation"
      ],
      "metadata": {
        "id": "8Fp6cfIqXEMc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll gather all the functions generate questions for an entirely new text.\n"
      ],
      "metadata": {
        "id": "FW1FcuG5Y4Sn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "IobRLZ90Z9Ho"
      }
    },
    {
      "source": [
        "import torch\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('punkt', quiet=True)\n",
        "\n",
        "class QuestionGenerator:\n",
        "    def __init__(self, model_name=\"valhalla/t5-base-qg-hl\"):\n",
        "        self.tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "        self.model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model.to(self.device)\n",
        "\n",
        "    def generate_questions(self, text, num_questions=5):\n",
        "        sentences = sent_tokenize(text)\n",
        "        questions = []\n",
        "\n",
        "        for sentence in sentences:\n",
        "            inputs = self.tokenizer.encode_plus(\n",
        "                f\"generate question: {sentence}\",\n",
        "                max_length=512,\n",
        "                padding=\"max_length\",\n",
        "                truncation=True,\n",
        "                return_tensors=\"pt\"\n",
        "            ).to(self.device)\n",
        "\n",
        "            outputs = self.model.generate(\n",
        "                input_ids=inputs[\"input_ids\"],\n",
        "                attention_mask=inputs[\"attention_mask\"],\n",
        "                max_length=64,\n",
        "                num_return_sequences=1,\n",
        "                num_beams=4,\n",
        "                early_stopping=True\n",
        "            )\n",
        "\n",
        "            question = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            questions.append({\"question\": question, \"answer\": sentence})\n",
        "\n",
        "            if len(questions) >= num_questions:\n",
        "                break\n",
        "\n",
        "        return questions[:num_questions]\n",
        "\n",
        "def main():\n",
        "    text = \"\"\"\n",
        "    Forrest Gump is a 1994 American comedy-drama film directed by Robert Zemeckis and written by Eric Roth.\n",
        "    It is based on the 1986 novel of the same name by Winston Groom and stars Tom Hanks, Robin Wright, Gary Sinise,\n",
        "    Mykelti Williamson and Sally Field. The story depicts several decades in the life of Forrest Gump (Hanks),\n",
        "    a slow-witted but kind-hearted man from Alabama who witnesses and unwittingly influences several defining\n",
        "    historical events in the 20th century United States. The film differs substantially from the novel.\n",
        "    \"\"\"\n",
        "\n",
        "    qg = QuestionGenerator()\n",
        "    questions = qg.generate_questions(text, num_questions=5)\n",
        "\n",
        "    for i, qa in enumerate(questions, 1):\n",
        "        print(f\"Question {i}:\")\n",
        "        print(f\"Q: {qa['question']}\")\n",
        "        print(f\"A: {qa['answer']}\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEyzFsqRi00O",
        "outputId": "923dd70d-623d-4afe-99e8-0102b21bbe6e"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question 1:\n",
            "Q: What is the name of the film that starred Robert Zemeckis?\n",
            "A: \n",
            "    Forrest Gump is a 1994 American comedy-drama film directed by Robert Zemeckis and written by Eric Roth.\n",
            "\n",
            "Question 2:\n",
            "Q: What is the name of the movie that stars Tom Hanks?\n",
            "A: It is based on the 1986 novel of the same name by Winston Groom and stars Tom Hanks, Robin Wright, Gary Sinise, \n",
            "    Mykelti Williamson and Sally Field.\n",
            "\n",
            "Question 3:\n",
            "Q: What is the name of Gump's character?\n",
            "A: The story depicts several decades in the life of Forrest Gump (Hanks), \n",
            "    a slow-witted but kind-hearted man from Alabama who witnesses and unwittingly influences several defining \n",
            "    historical events in the 20th century United States.\n",
            "\n",
            "Question 4:\n",
            "Q: What is the main difference between the film and the novel?\n",
            "A: The film differs substantially from the novel.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HERE WE GO! ALL IN ONE INFERENCE"
      ],
      "metadata": {
        "id": "BdrwDKuokCuy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer, LEDTokenizer, LEDForConditionalGeneration\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('punkt', quiet=True)\n",
        "\n",
        "class BlogProcessor:\n",
        "    def __init__(self):\n",
        "        self.qg_model_name = \"valhalla/t5-base-qg-hl\"\n",
        "        self.qg_tokenizer = T5Tokenizer.from_pretrained(self.qg_model_name)\n",
        "        self.qg_model = T5ForConditionalGeneration.from_pretrained(self.qg_model_name)\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.qg_model.to(self.device)\n",
        "\n",
        "        # Initialize heading generation model\n",
        "        self.hg_tokenizer = LEDTokenizer.from_pretrained(\"/content/drive/MyDrive/checkpoint-100\")\n",
        "        self.hg_model = LEDForConditionalGeneration.from_pretrained(\"/content/drive/MyDrive/checkpoint-100\").to(self.device).half()\n",
        "\n",
        "    def split_into_meaningful_paragraphs(self, text, min_sentences=3, max_sentences=10, similarity_threshold=0.3):\n",
        "        sentences = sent_tokenize(text)\n",
        "        paragraphs = []\n",
        "        current_paragraph = []\n",
        "        vectorizer = TfidfVectorizer()\n",
        "\n",
        "        for i, sentence in enumerate(sentences):\n",
        "            current_paragraph.append(sentence)\n",
        "\n",
        "            if len(current_paragraph) >= min_sentences:\n",
        "                if i + 1 < len(sentences):\n",
        "                    current_vec = vectorizer.fit_transform([' '.join(current_paragraph), sentences[i+1]])\n",
        "                    similarity = cosine_similarity(current_vec[0], current_vec[1])[0][0]\n",
        "\n",
        "                    if similarity < similarity_threshold or len(current_paragraph) >= max_sentences:\n",
        "                        paragraphs.append(' '.join(current_paragraph))\n",
        "                        current_paragraph = []\n",
        "\n",
        "        if current_paragraph:\n",
        "            paragraphs.append(' '.join(current_paragraph))\n",
        "\n",
        "        return paragraphs\n",
        "\n",
        "    def generate_heading(self, paragraph):\n",
        "        df = pd.DataFrame([paragraph], columns=['Paragraph'])\n",
        "        dataset = Dataset.from_pandas(df)\n",
        "\n",
        "        inputs_dict = self.hg_tokenizer(paragraph, padding=\"max_length\", max_length=512, return_tensors=\"pt\", truncation=True)\n",
        "        input_ids = inputs_dict.input_ids.to(self.device)\n",
        "        attention_mask = inputs_dict.attention_mask.to(self.device)\n",
        "        global_attention_mask = torch.zeros_like(attention_mask)\n",
        "\n",
        "        predicted_heading_ids = self.hg_model.generate(input_ids, attention_mask=attention_mask, global_attention_mask=global_attention_mask)\n",
        "        heading = self.hg_tokenizer.decode(predicted_heading_ids[0], skip_special_tokens=True)\n",
        "\n",
        "        return heading\n",
        "\n",
        "    def generate_questions(self, text, num_questions=5):\n",
        "        sentences = sent_tokenize(text)\n",
        "        questions = []\n",
        "\n",
        "        for sentence in sentences:\n",
        "            inputs = self.qg_tokenizer.encode_plus(\n",
        "                f\"generate question: {sentence}\",\n",
        "                max_length=512,\n",
        "                padding=\"max_length\",\n",
        "                truncation=True,\n",
        "                return_tensors=\"pt\"\n",
        "            ).to(self.device)\n",
        "\n",
        "            outputs = self.qg_model.generate(\n",
        "                input_ids=inputs[\"input_ids\"],\n",
        "                attention_mask=inputs[\"attention_mask\"],\n",
        "                max_length=64,\n",
        "                num_return_sequences=1,\n",
        "                num_beams=4,\n",
        "                early_stopping=True\n",
        "            )\n",
        "\n",
        "            question = self.qg_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            questions.append({\"question\": question, \"answer\": sentence})\n",
        "\n",
        "            if len(questions) >= num_questions:\n",
        "                break\n",
        "\n",
        "        return questions[:num_questions]\n",
        "\n",
        "    def process_blog(self, summary):\n",
        "        # Split into paragraphs\n",
        "        paragraphs = self.split_into_meaningful_paragraphs(summary)\n",
        "\n",
        "        structured_blog = []\n",
        "        all_questions = []\n",
        "\n",
        "        for paragraph in paragraphs:\n",
        "            # Generate heading\n",
        "            heading = self.generate_heading(paragraph)\n",
        "\n",
        "            # Generate questions\n",
        "            questions = self.generate_questions(paragraph, num_questions=2)\n",
        "\n",
        "            structured_blog.append(f\"## {heading}\\n\\n{paragraph}\")\n",
        "            all_questions.extend(questions)\n",
        "\n",
        "        # Combine everything\n",
        "        final_blog = \"\\n\\n\".join(structured_blog)\n",
        "        final_blog += \"\\n\\n## Questions for Review\\n\"\n",
        "        for i, qa in enumerate(all_questions, 1):\n",
        "            final_blog += f\"\\n{i}. Q: {qa['question']}\\n   A: {qa['answer']}\\n\"\n",
        "\n",
        "        return final_blog\n",
        "\n",
        "def main():\n",
        "    summary = \"\"\"\n",
        "    The Future of AI in Healthcare\n",
        "    Introduction: AI's Revolutionary Impact on Healthcare\n",
        "    Artificial Intelligence (AI) is poised to revolutionize the healthcare industry. From diagnosis to treatment planning, AI technologies are being integrated into various aspects of medical care. This integration promises to improve patient outcomes, reduce costs, and enhance the efficiency of healthcare systems worldwide.\n",
        "    Early Detection and Diagnosis\n",
        "    One of the most promising applications of AI in healthcare is in early detection and diagnosis of diseases. Machine learning algorithms can analyze medical images, such as X-rays, MRIs, and CT scans, with remarkable accuracy. These AI systems can often detect subtle abnormalities that might be overlooked by human radiologists, leading to earlier diagnoses and potentially life-saving interventions.\n",
        "    Personalized Treatment Plans\n",
        "    AI is also making significant strides in developing personalized treatment plans. By analyzing vast amounts of patient data, including genetic information, medical history, and lifestyle factors, AI algorithms can recommend tailored treatment options. This approach, known as precision medicine, allows healthcare providers to offer more effective and targeted therapies, minimizing side effects and improving overall patient care.\n",
        "    Drug Discovery and Development\n",
        "    The pharmaceutical industry is leveraging AI to accelerate drug discovery and development processes. Machine learning models can predict how potential drug compounds will interact with biological targets, significantly reducing the time and cost associated with traditional drug development methods. This could lead to faster development of new treatments for a wide range of diseases.\n",
        "    Administrative Efficiency and Cost Reduction\n",
        "    Beyond clinical applications, AI is also being used to streamline administrative tasks in healthcare settings. Natural language processing and machine learning algorithms can automate tasks such as medical coding, billing, and appointment scheduling. This not only reduces the administrative burden on healthcare professionals but also helps to minimize errors and improve overall efficiency.\n",
        "    Challenges and Ethical Considerations\n",
        "    While the potential benefits of AI in healthcare are immense, there are also significant challenges and ethical considerations to address. Issues such as data privacy, algorithmic bias, and the need for human oversight in AI-driven decision-making processes must be carefully managed. Ensuring that AI technologies are developed and implemented responsibly will be crucial for maintaining public trust and maximizing the benefits of these innovations.\n",
        "    Conclusion: A Collaborative Future\n",
        "    The future of AI in healthcare is not about replacing human medical professionals, but rather about augmenting their capabilities. By combining the analytical power of AI with the experience and intuition of healthcare providers, we can create a more effective, efficient, and patient-centered healthcare system. As AI continues to evolve, its impact on healthcare will undoubtedly grow, ushering in a new era of medical innovation and improved patient care.\n",
        "    \"\"\"\n",
        "\n",
        "    processor = BlogProcessor()\n",
        "    processed_blog = processor.process_blog(summary)\n",
        "    print(processed_blog)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfzfcxdBkGm7",
        "outputId": "731ce4f5-21f9-427b-f3cc-d2288f81d8d7"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Read more about AI in healthcare.\n",
            "\n",
            "\n",
            "    The Future of AI in Healthcare\n",
            "    Introduction: AI's Revolutionary Impact on Healthcare\n",
            "    Artificial Intelligence (AI) is poised to revolutionize the healthcare industry. From diagnosis to treatment planning, AI technologies are being integrated into various aspects of medical care. This integration promises to improve patient outcomes, reduce costs, and enhance the efficiency of healthcare systems worldwide. Early Detection and Diagnosis\n",
            "    One of the most promising applications of AI in healthcare is in early detection and diagnosis of diseases.\n",
            "\n",
            "## Artificial Intelligence (AI) is revolutionizing medical imaging.\n",
            "\n",
            "Machine learning algorithms can analyze medical images, such as X-rays, MRIs, and CT scans, with remarkable accuracy. These AI systems can often detect subtle abnormalities that might be overlooked by human radiologists, leading to earlier diagnoses and potentially life-saving interventions. Personalized Treatment Plans\n",
            "    AI is also making significant strides in developing personalized treatment plans.\n",
            "\n",
            "## Use AI to improve patient care.\n",
            "\n",
            "By analyzing vast amounts of patient data, including genetic information, medical history, and lifestyle factors, AI algorithms can recommend tailored treatment options. This approach, known as precision medicine, allows healthcare providers to offer more effective and targeted therapies, minimizing side effects and improving overall patient care. Drug Discovery and Development\n",
            "    The pharmaceutical industry is leveraging AI to accelerate drug discovery and development processes.\n",
            "\n",
            "## Machine learning can improve the delivery of drugs.\n",
            "\n",
            "Machine learning models can predict how potential drug compounds will interact with biological targets, significantly reducing the time and cost associated with traditional drug development methods. This could lead to faster development of new treatments for a wide range of diseases. Administrative Efficiency and Cost Reduction\n",
            "    Beyond clinical applications, AI is also being used to streamline administrative tasks in healthcare settings.\n",
            "\n",
            "## Use AI to automate healthcare tasks.\n",
            "\n",
            "Natural language processing and machine learning algorithms can automate tasks such as medical coding, billing, and appointment scheduling. This not only reduces the administrative burden on healthcare professionals but also helps to minimize errors and improve overall efficiency. Challenges and Ethical Considerations\n",
            "    While the potential benefits of AI in healthcare are immense, there are also significant challenges and ethical considerations to address.\n",
            "\n",
            "## Develop and implement AI-driven decisions.\n",
            "\n",
            "Issues such as data privacy, algorithmic bias, and the need for human oversight in AI-driven decision-making processes must be carefully managed. Ensuring that AI technologies are developed and implemented responsibly will be crucial for maintaining public trust and maximizing the benefits of these innovations. Conclusion: A Collaborative Future\n",
            "    The future of AI in healthcare is not about replacing human medical professionals, but rather about augmenting their capabilities.\n",
            "\n",
            "## Use AI to improve healthcare.\n",
            "\n",
            "By combining the analytical power of AI with the experience and intuition of healthcare providers, we can create a more effective, efficient, and patient-centered healthcare system. As AI continues to evolve, its impact on healthcare will undoubtedly grow, ushering in a new era of medical innovation and improved patient care.\n",
            "\n",
            "## Questions for Review\n",
            "\n",
            "1. Q: What is the future of AI in healthcare?\n",
            "   A: \n",
            "    The Future of AI in Healthcare\n",
            "    Introduction: AI's Revolutionary Impact on Healthcare\n",
            "    Artificial Intelligence (AI) is poised to revolutionize the healthcare industry.\n",
            "\n",
            "2. Q: AI technologies are being integrated into various aspects of medical care?\n",
            "   A: From diagnosis to treatment planning, AI technologies are being integrated into various aspects of medical care.\n",
            "\n",
            "3. Q: Machine learning algorithms can analyze medical images with remarkable accuracy?\n",
            "   A: Machine learning algorithms can analyze medical images, such as X-rays, MRIs, and CT scans, with remarkable accuracy.\n",
            "\n",
            "4. Q: AI systems can detect subtle abnormalities that might be overlooked by human radiologists?\n",
            "   A: These AI systems can often detect subtle abnormalities that might be overlooked by human radiologists, leading to earlier diagnoses and potentially life-saving interventions.\n",
            "\n",
            "5. Q: What can AI algorithms use to recommend treatment options?\n",
            "   A: By analyzing vast amounts of patient data, including genetic information, medical history, and lifestyle factors, AI algorithms can recommend tailored treatment options.\n",
            "\n",
            "6. Q: What is precision medicine?\n",
            "   A: This approach, known as precision medicine, allows healthcare providers to offer more effective and targeted therapies, minimizing side effects and improving overall patient care.\n",
            "\n",
            "7. Q: Machine learning models can predict how potential drug compounds will interact with biological targets?\n",
            "   A: Machine learning models can predict how potential drug compounds will interact with biological targets, significantly reducing the time and cost associated with traditional drug development methods.\n",
            "\n",
            "8. Q: What could lead to faster development of new treatments for a wide range of diseases?\n",
            "   A: This could lead to faster development of new treatments for a wide range of diseases.\n",
            "\n",
            "9. Q: Natural language processing and machine learning algorithms can automate tasks such as billing and appointment scheduling.\n",
            "   A: Natural language processing and machine learning algorithms can automate tasks such as medical coding, billing, and appointment scheduling.\n",
            "\n",
            "10. Q: What does this reduce the administrative burden on healthcare professionals?\n",
            "   A: This not only reduces the administrative burden on healthcare professionals but also helps to minimize errors and improve overall efficiency.\n",
            "\n",
            "11. Q: What must be carefully managed in AI-driven decision making processes?\n",
            "   A: Issues such as data privacy, algorithmic bias, and the need for human oversight in AI-driven decision-making processes must be carefully managed.\n",
            "\n",
            "12. Q: What is crucial for maintaining public trust and maximizing the benefits of AI technologies?\n",
            "   A: Ensuring that AI technologies are developed and implemented responsibly will be crucial for maintaining public trust and maximizing the benefits of these innovations.\n",
            "\n",
            "13. Q: What can AI do to create a more effective healthcare system?\n",
            "   A: By combining the analytical power of AI with the experience and intuition of healthcare providers, we can create a more effective, efficient, and patient-centered healthcare system.\n",
            "\n",
            "14. Q: What is the impact of AI on healthcare?\n",
            "   A: As AI continues to evolve, its impact on healthcare will undoubtedly grow, ushering in a new era of medical innovation and improved patient care.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}